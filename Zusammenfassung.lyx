#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Zusammenfassung Machine Learning HS 17
\end_layout

\begin_layout Section
Supervised Learning
\end_layout

\begin_layout Standard
Given some data, we want to be able to predict the outcome.
 E.g.
 when we have the Living area, we may want to predict the price of a house
 as a function of the size of the living area.
 
\end_layout

\begin_layout Standard
To establish a notation, we'll use 
\begin_inset Formula $x^{(i)}$
\end_inset

 to denote the input variables (the living area in our example).
 These are also called 
\series bold
input features
\series default
.
 We'll use 
\begin_inset Formula $y^{(i)}$
\end_inset

 to denote the output, which is also called 
\series bold
target variable
\series default
.
 A pair 
\begin_inset Formula $(x^{(i)},y^{(i)})$
\end_inset

 is then called a 
\series bold
training example 
\series default
and the whole list of training examples we're using is called the 
\series bold
training set
\series default
.
 The i says that this is the i-th training example.
 
\end_layout

\begin_layout Standard
Our goal is, given a training set, to find a function 
\begin_inset Formula $h$
\end_inset

 so that 
\begin_inset Formula $h(x)$
\end_inset

 predicts 
\begin_inset Formula $y$
\end_inset

 
\begin_inset Quotes eld
\end_inset

accuratly
\begin_inset Quotes erd
\end_inset

.
 This function 
\begin_inset Formula $h(x)$
\end_inset

 is called a 
\series bold
hypothesis
\series default
.
 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ../../Machine Learning/hypothesis.png

\end_inset


\end_layout

\begin_layout Standard
When the target variable that we're trying to predict is continuous (can
 take on infinitely many, uncountable values), we call the learning problem
 a 
\series bold
regression problem
\series default
.
 When 
\begin_inset Formula $y$
\end_inset

 can take on only a small number of discrete values, we call it a 
\series bold
classification problem.
 
\end_layout

\begin_layout Subsection
Linear Regression
\end_layout

\begin_layout Standard
To perform supervised learning, we must decide how to represent our hypothesis
 
\begin_inset Formula $h$
\end_inset

.
 As an inital choice, we're going to approximate 
\begin_inset Formula $y$
\end_inset

 as a linear function of 
\begin_inset Formula $x$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
h_{\Theta}(x)=\sum_{i=0}^{n}\Theta_{i}x_{i}=\Theta^{T}x
\]

\end_inset


\begin_inset Newline newline
\end_inset

The 
\begin_inset Formula $\Theta_{i}$
\end_inset

's are the 
\series bold
parameters
\series default
 or the 
\series bold
weights
\series default
 which parameterize our functions mapping from the 
\series bold
feature space 
\begin_inset Formula $X$
\end_inset

 
\series default
to the 
\series bold
target space
\series default
 
\begin_inset Formula $Y$
\end_inset

.
 Note, that 
\begin_inset Formula $x_{0}$
\end_inset

(also called the 
\series bold
intercept term
\series default
) is always equal to 1 to simplify our notation.
 On the right-hand side of the equation above, we use both 
\begin_inset Formula $\Theta$
\end_inset

and 
\begin_inset Formula $x$
\end_inset

 as vectors to simplify the math.
 
\end_layout

\begin_layout Standard
Now how are we going to learn our parameters 
\begin_inset Formula $\Theta$
\end_inset

? We will try to make 
\begin_inset Formula $h(x)$
\end_inset

 to be as close to 
\begin_inset Formula $y$
\end_inset

 as possible for the training examples we have.
 To do this, we define the 
\series bold
cost function
\series default
, which measures how close the 
\begin_inset Formula $h(x^{(i)})$
\end_inset

's are to the corresponding 
\begin_inset Formula $y^{(i)}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
J(\Theta)=\frac{1}{2}\sum_{i=1}^{m}(h_{\Theta}(x^{(i)})-y^{(i)})^{2}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
LMS algorithm
\end_layout

\begin_layout Standard
We want to choose 
\begin_inset Formula $\Theta$
\end_inset

so as to make 
\begin_inset Formula $J(\Theta)$
\end_inset

 as small as possible.
 We start by choosing some initial guess for 
\begin_inset Formula $\Theta$
\end_inset

and then we repeatedly change 
\begin_inset Formula $\Theta$
\end_inset

to minimize 
\begin_inset Formula $J(\Theta)$
\end_inset

 step by step.
 We now look at the 
\series bold
gradient descent 
\series default
algorithm that does exactly that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Theta_{j}:=\Theta_{j}-\alpha\frac{\partial}{\partial}J(\Theta)
\]

\end_inset

where 
\begin_inset Formula $\alpha$
\end_inset

is the 
\series bold
learning rate
\series default
.
 This way w're going stepwise in the direction of steepest descrease of
 J.
 For a single training example, we get the update rule:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Theta_{j}:=\Theta_{j}+\alpha(y^{(i)}-h_{\Theta}(x^{(i)}))x_{j}^{(i)}
\]

\end_inset

This rule is called the 
\series bold
LMS (least mean square)
\series default
 update rule.
 It is proportional to the error term 
\begin_inset Formula $(y^{(i)}-h_{\Theta}(x^{(i)}))$
\end_inset

 so for small errors w're only going to make small adjustments whereas we're
 going to make bigger adjustments for bigger errors.
\end_layout

\begin_layout Standard
The adjustment to the whole training set is quite simple:
\end_layout

\begin_layout Standard
\begin_inset space \qquad{}
\end_inset

Loop {
\end_layout

\begin_layout Standard
\begin_inset space \qquad{}
\end_inset


\begin_inset space \qquad{}
\end_inset

for i=1 to m, {
\end_layout

\begin_layout Standard
\begin_inset space \qquad{}
\end_inset


\begin_inset space \qquad{}
\end_inset


\begin_inset space \qquad{}
\end_inset


\begin_inset Formula $\Theta_{j}:=\Theta_{j}+\alpha(y^{(i)}-h_{\Theta}(x^{(i)}))x_{j}^{(i)}$
\end_inset

 (for every j)
\end_layout

\begin_layout Standard
\begin_inset space \qquad{}
\end_inset


\begin_inset space \qquad{}
\end_inset

}
\end_layout

\begin_layout Standard
\begin_inset space \qquad{}
\end_inset

}
\end_layout

\begin_layout Standard
We repeatedly run through the training set and for each training example
 we update all he parameters.
 This algorithm is called 
\series bold
stochastic gradient descent 
\series default
or 
\series bold
incremental gradient descent
\series default
.
 
\end_layout

\begin_layout Standard
Another option is the 
\series bold
batch gradient descent
\series default
:
\end_layout

\begin_layout Standard
\begin_inset space \qquad{}
\end_inset

Repeat until convergence{
\begin_inset Formula 
\[
\Theta_{j}:=\Theta_{j}+\alpha\sum_{i=1}^{m}(y^{(i)}-h_{\Theta}(x^{(i)}))x_{j}^{(i)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset space \qquad{}
\end_inset

}
\end_layout

\begin_layout Standard
Stochastic gradient is often preferred to batch gradient because whereas
 batch gradient has to scan over the whole training set (which can get costly
 for large m), stochastic gradient can start right away with the first training
 example.
 Note, that stochastic gradient doesn't reach a global minimum (as batch
 gradient) but oscillates around an optimal solution.
 
\end_layout

\begin_layout Subsection
The normal equations
\end_layout

\begin_layout Standard
We will now see another way to minimize 
\begin_inset Formula $J$
\end_inset

.
 In this method we' re going to take the derivatives of 
\begin_inset Formula $J$
\end_inset

 with respect to the 
\begin_inset Formula $\Theta_{j}$
\end_inset

's and set them to zero.
 First we're repeating some rules to simplify our math.
\end_layout

\begin_layout Subsubsection
Matrix derivatives
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nabla_{A}f(A)=\left[\begin{array}{ccc}
\frac{\partial f}{\partial A_{11}} & \dots & \frac{\partial f}{\partial A_{1n}}\\
\vdots & \ddots & \vdots\\
\frac{\partial f}{\partial A_{m1}} & \dots & \frac{\partial f}{\partial A_{mn}}
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
tr(A)=tr(A^{T})
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
tr(ABCD)=tr(DABC)=tr(CDAB)=tr(BCDA)
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Least squares revisited
\end_layout

\begin_layout Standard
Given a training set, we define the 
\series bold
design matrix
\series default
 X to be the matrix containing all training examples, where the i-th training
 example is the i-th row.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X=\left[\begin{array}{c}
(x^{(1)})^{T}\\
\vdots\\
(x^{(m)})^{T}
\end{array}\right]
\]

\end_inset

Let 
\begin_inset Formula $\overrightarrow{y}$
\end_inset

be the m-dimensional vector containing all target values from the training
 set.
 Using math rules and the formula we got in the last section we get
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nabla_{\Theta}J(\Theta)=X^{T}X\Theta-X^{T}y
\]

\end_inset

Therefore the value of 
\begin_inset Formula $\Theta$
\end_inset

that minimizes 
\begin_inset Formula $J(\Theta)$
\end_inset

 is given by the equation
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Theta=(X^{T}X)^{-1}X^{T}y
\]

\end_inset


\end_layout

\begin_layout Subsection
Probabilistic interpretation
\end_layout

\begin_layout Standard
We will now look at linear regression under terms of probabilistic assumptions.
 To start, we assume that the target variable and the inputs are related
 via
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y^{(i)}=\Theta^{T}x^{(i)}+\epsilon^{(i)}
\]

\end_inset

where 
\begin_inset Formula $\epsilon^{(i)}$
\end_inset

 is an error term that is distributed IID (independently and identically
 distributed) according to a Gaussian distribution with mean 0 and variance
 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
 We write this as 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $\epsilon^{(i)}\sim N(0,\sigma^{2})."$
\end_inset

 This implies that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(y^{(i)}|\,x^{(i)};\Theta)=\frac{1}{\sqrt{2\pi}\sigma}exp\left(-\frac{(y^{(i)}-\Theta^{T}x^{(i)})^{2}}{2\sigma^{2}}\right)
\]

\end_inset

This follows from the densitiy of 
\begin_inset Formula $\epsilon^{(i)}$
\end_inset

.
 The notation 
\begin_inset Formula $p(y^{(i)}|\:x^{(i)};\Theta)$
\end_inset

 indicates the distribution of 
\begin_inset Formula $y^{(i)}$
\end_inset

given 
\begin_inset Formula $x^{(i)}$
\end_inset

, parameterized by 
\begin_inset Formula $\Theta$
\end_inset

.
 Getting back to our whole training set we can also write the probability
 of the whole data as 
\begin_inset Formula $p(y|\:X;\Theta)$
\end_inset

.
 When we wish to see this as a function of 
\begin_inset Formula $\Theta$
\end_inset

, we will call it the 
\series bold
likelihood
\series default
 function:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L(\Theta)=L(\Theta;X,y)=p(y|\,X;\Theta)
\]

\end_inset

Because of our assumption of independence for the 
\begin_inset Formula $\epsilon^{(i)}$
\end_inset

, this can also be written as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L(\Theta)=\prod_{i=1}^{m}p(y^{(i)}|\:x^{(i)};\Theta)=\prod_{i=1}^{m}\frac{1}{\sqrt{2\pi}\sigma}exp\left(-\frac{(y^{(i)}-\Theta^{T}x^{(i)})^{2}}{2\sigma^{2}}\right)
\]

\end_inset

The principal of 
\series bold
maximum likelihood
\series default
 says that we should choose 
\begin_inset Formula $\Theta$
\end_inset

so as to make the data as high probability as possible.
 Therefore we should choose 
\begin_inset Formula $\Theta$
\end_inset

to maximize 
\begin_inset Formula $L(\Theta)$
\end_inset

.
 To make our calculations simpler we will instead of maximizing 
\begin_inset Formula $L(\Theta)$
\end_inset

maximize a strictly increasing function of 
\begin_inset Formula $L(\Theta)$
\end_inset

, in our case the 
\series bold
log likelihood
\series default
 
\begin_inset Formula $l(\Theta)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
l(\Theta)=log\,L(\Theta)=m\,log\frac{1}{\sqrt{2\pi}\sigma}-\frac{1}{\sigma^{2}}\cdot\frac{1}{2}\sum_{i=1}^{m}(y^{(i)}-\Theta^{T}x^{(i)})^{2}
\]

\end_inset

Hence, maximizing 
\begin_inset Formula $l(\Theta)$
\end_inset

gives the same answer as maximizing 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{1}{2}\sum_{i=1}^{m}(y^{(i)}-\Theta^{T}x^{(i)})^{2},
\]

\end_inset

which is our original 
\begin_inset Formula $J(\Theta)$
\end_inset

, the cost function from least-square.
 
\end_layout

\begin_layout Section
Classification and logistic regression
\end_layout

\begin_layout Standard
Classification is quite similar to the regression problem, but now our values
 
\begin_inset Formula $y$
\end_inset

 take on only a small number of discrete values.
 To start, we will focus on the 
\series bold
inary classification
\series default
 problem, where 
\begin_inset Formula $y$
\end_inset

 can only take on 1 and 0.
 Given 
\begin_inset Formula $x^{(i)}$
\end_inset

, the corresponding 
\begin_inset Formula $y^{(i)}$
\end_inset

is also called the 
\series bold
label
\series default
 for the training example.
 
\end_layout

\begin_layout Subsection
Logistic regression
\end_layout

\begin_layout Standard
If we would use our already known linear regression algorithm to predict
 
\begin_inset Formula $y$
\end_inset

 given 
\begin_inset Formula $x$
\end_inset

, we would see that this method performs rather poorly.
 It also makes no sense that 
\begin_inset Formula $h_{\Theta}(x)$
\end_inset

 can take on values outside of 
\begin_inset Formula $[0,1]$
\end_inset

.
 To fix this we will change our hypothesis:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
h_{\Theta}(x)=g(\Theta^{T}x)=\frac{1}{1+e^{-\Theta^{T}x}}
\]

\end_inset

where
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
g(z)=\frac{1}{1+e^{-z}}
\]

\end_inset

is called the 
\series bold
logistic function
\series default
 or the 
\series bold
sigmoid function
\series default
.
 As you can see, 
\begin_inset Formula $g(z)$
\end_inset

 tends to 1 for large values of z and to 0 for small values of z.
 The derivative of the sigmoid function is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
g'(z)=g(z)(1-g(z)).
\]

\end_inset


\end_layout

\begin_layout Standard
Similar as before we will now make a set of probabilistic assumptions and
 then fit our parameters via maximum lieklihood.
 Let us assume that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(y=1|\,x;\Theta)=h_{\Theta}(x)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(y=0|\,x;\Theta)=1-h_{\Theta}(x)
\]

\end_inset

 Therefore
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(y|x;\Theta)=(h_{\Theta}(x))^{y}(1-h_{\Theta}(x))^{1-y}
\]

\end_inset

Again, assuming that our 
\begin_inset Formula $m$
\end_inset

 training examples ar IID, the likelihood of the parameters is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L(\Theta)=\prod_{i=1}^{m}(h_{\Theta}(x^{(i)}))^{y^{(i)}}(1-h_{\Theta}(x^{(i)}))^{1-y^{(i)}}
\]

\end_inset

As before, we will again maximize the log likelihood
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
l(\Theta)=log\,L(\Theta)=\sum_{i=1}^{m}y^{(i)}log\,h(x^{(i)})+(1-y^{(i)})log(1-h(x^{(i)}))
\]

\end_inset


\end_layout

\begin_layout Standard
How do we maximize the likelihood? Similar as with linear regression we
 can use gradient ascent.
 In vectorial notation, our updates will be given by 
\begin_inset Formula $\Theta:=\Theta+\alpha\nabla_{\Theta}l(\Theta)$
\end_inset

 where 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial\Theta_{j}}l(\Theta)=(y-h_{\Theta}(x))x_{j}
\]

\end_inset

This gives us therefore the stochastic gradient ascent rule
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Theta_{j}:=\Theta_{j}+\alpha(y^{(i)}-h_{\Theta}(x^{(i)}))x_{j}^{(i)}
\]

\end_inset


\end_layout

\begin_layout Subsection
The perceptron learning algorithm
\end_layout

\begin_layout Standard
We want to be able to 
\begin_inset Quotes eld
\end_inset

force
\begin_inset Quotes erd
\end_inset

 our algorithm to output values that are either exactly 1 or 0.
 We can do this by modifying 
\begin_inset Formula $g(z)$
\end_inset

so that it's outputing 1 if 
\begin_inset Formula $z\ge0$
\end_inset

 and 0 if 
\begin_inset Formula $z<0$
\end_inset

.
 If we then let 
\begin_inset Formula $h_{\Theta}(x)=g(\Theta^{T}x)$
\end_inset

 and use the same update rule as above, we have the 
\series bold
perceptron learning algorithm
\series default
.
 
\end_layout

\begin_layout Subsection
Another algorithm for maximizing 
\begin_inset Formula $l(\Theta)$
\end_inset


\end_layout

\begin_layout Standard
First, consider Newton's method for finding a zero of a function.
 The update rule here is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Theta:=\Theta-\frac{f(\Theta)}{f'(\Theta)}
\]

\end_inset

Here, we're approximating the minimum by taking the tangent of the function,
 going through the current guess of 
\begin_inset Formula $\Theta$
\end_inset

.
 The point where this tangent is zero becomes our new guess.
 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename newton_graphs.png

\end_inset


\end_layout

\begin_layout Standard
This method gives us a way to get to 
\begin_inset Formula $f(\Theta)=0.$
\end_inset

 But we want to use it to maximize a function.
 The maxima of this function 
\begin_inset Formula $l$
\end_inset

 correspond to points where the first derivative is zero.
 Therefore we obtain the update rule
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Theta:=\Theta-\frac{l'(\Theta)}{l''(\Theta)}
\]

\end_inset

The generalization if this method to the multidimensional setting is given
 by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Theta:=\Theta-H^{-1}\nabla_{\Theta}l(\Theta)
\]

\end_inset

where 
\begin_inset Formula $H$
\end_inset

 is the Hessian which is given by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
H_{ij}=\frac{\partial^{2}l(\Theta)}{\partial\Theta_{i}\partial\Theta_{j}}.
\]

\end_inset

 Usually, Newton's method converges much faster than gradiant descent and
 needs fewer iterations.
 But for large numbers of features this method can get very costly because
 the inverse of a big matrix needs to be calulated.
 When Newton's method is applied to maximize the logistic regression log
 likelihood function 
\begin_inset Formula $l(\Theta)$
\end_inset

, the resulating method is also called 
\series bold
Fisher scoring
\series default
.
 
\end_layout

\begin_layout Section
Generative Learning algorithms
\end_layout

\begin_layout Standard
So far we always modelled 
\begin_inset Formula $p(y|x)$
\end_inset

.
 Now we want to learn 
\begin_inset Formula $p(x|y)$
\end_inset

.
 For example, if 
\begin_inset Formula $y$
\end_inset

 indicates whetere an example is a dog (0) or an elephant (1), then 
\begin_inset Formula $p(x|y=0)$
\end_inset

 models the distribution of the dogs' features.
 After modeling 
\begin_inset Formula $p(y)$
\end_inset

 (called 
\series bold
class priors
\series default
) and 
\begin_inset Formula $p(x|y)$
\end_inset

 our algorithm can then use Bayes rule to derive the posterior distribution
 on 
\begin_inset Formula $y$
\end_inset

 given 
\begin_inset Formula $x$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(y|x)=\frac{p(x|y)p(y)}{p(x)}
\]

\end_inset


\end_layout

\begin_layout Subsection
Gaussian discriminant analysis GDA
\end_layout

\begin_layout Standard
This model assumes that 
\begin_inset Formula $p(x|y)$
\end_inset

 is distributed according to a multivariate normal distribution.
 
\end_layout

\begin_layout Subsubsection
Multivariate Normal Distribution
\end_layout

\begin_layout Standard
The multivariate normal distribution in 
\begin_inset Formula $n$
\end_inset

-dimensions is parameterized by a 
\series bold
mean vector
\series default
 
\begin_inset Formula $\mu\in\mathbb{{R}}^{n}$
\end_inset

and a 
\series bold
covariance matrix 
\series default

\begin_inset Formula $\Sigma\in\mathbb{R}^{n\,x\,n}$
\end_inset

 where 
\begin_inset Formula $\Sigma$
\end_inset

is symmetric and positive definitve.
 The density (also written as 
\begin_inset Formula $N(\mu,\Sigma)$
\end_inset

) is given by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(x;\mu,\Sigma)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp(-\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu))
\]

\end_inset

The mean of this density is of course 
\begin_inset Formula $\mu$
\end_inset

.
 The 
\series bold
covariance
\series default
 of a vector-valued random variable 
\begin_inset Formula $Z$
\end_inset

 is defined as Cov(
\begin_inset Formula $Z$
\end_inset

)=E[(Z-E[Z])(Z-E[Z])
\begin_inset Formula $^{T}$
\end_inset

] If X is distributed according to a multivariate normal distribution, then
 
\begin_inset Formula $Cov(X)=\Sigma$
\end_inset

.
\end_layout

\begin_layout Standard
Graphically spoken, the covariance matrix changes the shape of the ellipsoid
 where mean moves the center:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename vary_sigma.png

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename vary_mu.png

\end_inset


\end_layout

\begin_layout Subsubsection
The Gaussian Discriminant Analysis model
\end_layout

\begin_layout Standard
The model is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y\sim Bernoulli(\phi)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
x|y=0\sim N(\mu_{0},\Sigma)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
x|y=1\sim N(\mu_{1},\Sigma)
\]

\end_inset

The parameters of our model here are 
\begin_inset Formula $\phi,\Sigma,\mu_{0}$
\end_inset

and 
\begin_inset Formula $\mu_{1}$
\end_inset

.The log-likelihood of the data is given by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
l(\phi,\mu_{0,}\mu_{1},\Sigma)=log\prod_{i=1}^{m}p(x^{(i)},y^{(i)};\phi,\mu_{0},\mu_{1},\Sigma)
\]

\end_inset

When we maximize 
\begin_inset Formula $l$
\end_inset

 with respect to the parameters we find he maximum likelihood estimates
 of the parameters to be:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi=\frac{1}{m}\sum_{i=1}^{m}1\{y^{(i)}=1\}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mu_{0}=\frac{\sum_{i=1}^{m}1\{y^{(i)}=0\}x^{(i)}}{\sum_{i=1}^{m}1\{y^{(i)}=0\}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mu_{1}=\frac{\sum_{i=1}^{m}1\{y^{(i)}=1\}x^{(i)}}{\sum_{i=1}^{m}1\{y^{(i)}=1\}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Sigma=\frac{1}{m}\sum_{i=1}^{m}(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-u_{y^{(i)}})^{T}
\]

\end_inset

The following image shows what the algorithm is doing:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename gda.png

\end_inset


\end_layout

\begin_layout Standard
The data has been fit to the two gaussians we see here.
 One is for the data that is an x, the other is for the data that is a circle.
 Also shown is the decision boundardy where 
\begin_inset Formula $p(y=1|x)=0.5$
\end_inset

.
 On one side we predict 
\begin_inset Formula $y=1$
\end_inset

, on the other we predict 
\begin_inset Formula $y=0$
\end_inset

.
 The gaussians have the same shape because they have the same covariance
 matrix but their mean 
\begin_inset Formula $\mu_{0},\mu_{1}$
\end_inset

is different .
 
\end_layout

\begin_layout Subsubsection
Discussion: GDA and logistic regression
\end_layout

\begin_layout Standard
We can view 
\begin_inset Formula $p(y=1|x;\phi,\mu_{0},\mu_{1},\Sigma)$
\end_inset

 as a function of x and will find that in can be expressed in the form
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(y=1|x;\phi,\Sigma,\mu_{0},\mu_{1})=\frac{1}{1+exp(-\Theta^{T}x)}
\]

\end_inset

where 
\begin_inset Formula $\Theta$
\end_inset

is some appropriate function of the remainin parameters.
 This is the form that logistic regression used to model 
\begin_inset Formula $p(y=1|x)$
\end_inset

.
 When do we prefer one model over the other?
\end_layout

\begin_layout Standard
GDA makes 
\emph on
stronger
\emph default
 modeling assumptions than logistic regression does.
 It turns out that when these assumptions are correct, GDA will find better
 fits to the data.
 This is especially the case when 
\begin_inset Formula $p(x|y)$
\end_inset

 is gaussian.
 But by making weaker assumptions, logistic regression is more 
\emph on
robust
\emph default
 and less sensitive to wrong assumptions than GDA.
 So if we assumed that 
\begin_inset Formula $p(y|x)$
\end_inset

 is logistic and 
\begin_inset Formula $x|y\sim Poisson$
\end_inset

 then GDA may not do well on such non-Gaussian data.
 GDA makes more assumptions and is more data-efficient when the modeling
 assumptions are (at least approximately) correct.
 Logistic regression makes weaker assumptions and is more robust.
 Especially in non-Gaussian data, logistic regression will do better than
 GDA.
\end_layout

\begin_layout Subsection
Naive Bayes
\end_layout

\begin_layout Standard
GDA works with continuous, real-valued vectors.
 This is a different learning algorithm where the 
\begin_inset Formula $x_{i}$
\end_inset

's are discrete-valued.
 To demonstrate, assume we're gonna build an spam-filter.
\end_layout

\begin_layout Standard
We will represent an email via a feature vector whose length is equal to
 the length of the dictionary.
 If an email contains word number 
\begin_inset Formula $i$
\end_inset

 in the dictionary, then 
\begin_inset Formula $x_{i}=1$
\end_inset

, otherwise 
\begin_inset Formula $x_{i}=0$
\end_inset

.
 The words in the feature vector are called 
\series bold
vocabulary
\series default
.
 We want to model 
\begin_inset Formula $p(x|y)$
\end_inset

.
 This means that given spam or not spam, how possible is it that word 
\begin_inset Formula $i$
\end_inset

 is going to show up.
 To model 
\begin_inset Formula $p(x|y)$
\end_inset

 we're going to make a very strong assumption.
 We will assume that the 
\begin_inset Formula $x_{i}$
\end_inset

's are conditionally independent given 
\begin_inset Formula $y$
\end_inset

.
 This assumption is called the 
\series bold
Naive Bayes (NB) assumption
\series default
 and the resulting algorithm is called the 
\series bold
Naive Bayes classifier.
 
\series default
This means that when we have 
\begin_inset Formula $y=1$
\end_inset

, the knowledge of 
\begin_inset Formula $x_{2987}$
\end_inset

makes no effect on the knowledge of 
\begin_inset Formula $x_{19}$
\end_inset

.
 This can also be written as 
\begin_inset Formula $p(x_{2987}|y)=p(x_{2987}|y,x_{19})$
\end_inset

 (this is different from saying they are independet what would mean 
\begin_inset Formula $p(x_{2987})=p(x_{2987}|x_{19})$
\end_inset

).
 
\end_layout

\begin_layout Standard
We now have 
\begin_inset Formula $p(x_{1},\dots,x_{n}|y)=\prod_{i=1}^{n}p(x_{i}|y)$
\end_inset


\end_layout

\begin_layout Standard
Note that even though we made a strong assumptions, NB still works well
 on many problems.
 
\end_layout

\begin_layout Standard
Our model is parameterized by 
\begin_inset Formula $\phi_{i|y=1}=p(x_{i}=1|y=1)$
\end_inset

, 
\begin_inset Formula $\phi_{i|y=0}=p(x_{i}=1|y=0)$
\end_inset

 and 
\begin_inset Formula $\phi_{y}=p(y=1)$
\end_inset

.
 When we write down the joint likelihood of the data we get
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L(\phi_{y},\phi_{i|y=0},\phi_{i|y=1})=\prod_{i=1}^{m}p(x^{(i)},y^{(i)})
\]

\end_inset

Maximizing this results in the maximum likelihood estimates:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi_{j|y=1}=\frac{\sum_{i=1}^{m}1\{x_{j}^{(i)}=1\land y^{(i)}=1\}}{\sum_{i=1}^{m}1\{y^{(i)}=1\}}
\]

\end_inset

(How many times does the word show up in spam email in contrast to all spam
 email?)
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi_{j|y=0}=\frac{\sum_{i=1}^{m}1\{x_{j}^{(i)}=1\land y^{(i)}=0\}}{\sum_{i=1}^{m}1\{y^{(i)}=0\}}
\]

\end_inset

(How many times does the word show up in non-spam email in contrast to all
 non-spam email?)
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi_{y}=\frac{\sum_{i=1}^{m}1\{y^{(i)}=1\}}{m}
\]

\end_inset


\end_layout

\begin_layout Standard
Now that we have fit all our data, to make a prediction we simply have to
 calculate
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(y=1|x)=\frac{p(x|y=1)p(y=1)}{p(x)}=\frac{(\prod_{i=1}^{n}p(x_{i}|y=1))p(y=1)}{(\prod_{i=1}^{n}p(x_{i}|y=1))p(y=1)+(\prod_{i=1}^{n}p(x_{i}|y=0))p(y=0)}=\frac{(\prod_{i=1}^{n}\phi_{i|y=1})\phi_{y}}{(\prod_{i=1}^{n}\phi_{i|y=1})\phi_{y}+(\prod_{i=1}^{n}\phi_{i|y=0})(1-\phi_{y})}
\]

\end_inset


\end_layout

\begin_layout Standard
Note that even though this example was with binary values, the generalization
 to a case where 
\begin_inset Formula $x_{i}$
\end_inset

can take on values in {1,2,...,k} is straightforward.
 We could just model 
\begin_inset Formula $p(x_{i}|y)$
\end_inset

 as multinomial rather than as Bernoulli.
 It is in practice quite common to 
\series bold
discretize
\series default
 and then use Naive Bayes.
 When original, contiuous-valued attributes are not well-modeled by a multivaria
te normal distribution, discretizing the features and using Naive Bayes
 will often result in a better classifier.
 
\end_layout

\begin_layout Subsubsection
Laplace smoothing 
\end_layout

\begin_layout Standard
Assume a word our algorithm has never seen shows up.
 Because it has not seen it before it will decide the probability to be
 zero for spam and non-spam mail what will will lead to 
\begin_inset Formula $\frac{0}{0}$
\end_inset

 division: Our algorithm doesn't know how to predict this case.
 To take account of such new words we can use 
\series bold
Laplace smoothing: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi_{j}=\frac{(\sum_{i=1}^{m}1\{z^{(i)}=1\})+1}{m+k}
\]

\end_inset

 where k is the maximum value z can take on.
 Returning to our Naive Bayes classifier with Laplace smoothing we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi_{j|y=1}=\frac{\sum_{i=1}^{m}1\{x_{j}^{(i)}=1\land y^{(i)}=1\}+1}{\sum_{i=1}^{m}1\{y^{(i)}=1\}+2}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi_{j|y=0}=\frac{\sum_{i=1}^{m}1\{x_{j}^{(i)}=1\land y^{(i)}=0\}+1}{\sum_{i=1}^{m}1\{y^{(i)}=0\}+2}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Event models for text classification
\end_layout

\begin_layout Standard
We'll look at one more model for text classification.
 In the last chapter we assumed that first it is randomly determined whether
 the next mail is from a spammer or a non-spammer.
 Then the person sending the mail runs through the dictionary deciding whether
 to use or not use the word 
\begin_inset Formula $i$
\end_inset

 according to the probabilities 
\begin_inset Formula $\phi_{i|y}$
\end_inset

.
 Now we take a look at the 
\series bold
multinomial event model.
\end_layout

\begin_layout Standard
\begin_inset Formula $x_{i}$
\end_inset

will now denote the identitiy of the 
\begin_inset Formula $i$
\end_inset

-th word in the email.
 Thus, 
\begin_inset Formula $x_{i}$
\end_inset

can now take on values from 1 to 
\begin_inset Formula $|V|$
\end_inset

 where 
\begin_inset Formula $V$
\end_inset

 is the dictionary.
 
\begin_inset Formula $(1,17,...)$
\end_inset

 means the first word in the mail is the first from the dictionary, the
 second word is the 17-th from the dictionary, etc.
 Now again, it is first decided whether it is a spam mail or not.
 Then, the sender of the email writes the email by generating 
\begin_inset Formula $x_{1}$
\end_inset

from some multinomial distribution over words, then chooses 
\begin_inset Formula $x_{2}$
\end_inset

the same way but independently, etc.
 The overall probability of a message is then given by 
\begin_inset Formula $p(y)\prod_{i=1}^{n}p(x_{i}|y)$
\end_inset

.
 This looks similar as before but the terms in the formula mean now different
 things and in particular, 
\begin_inset Formula $x_{i}|y$
\end_inset

 is now multinomial, rather than Bernoulli.
 
\end_layout

\begin_layout Standard
The parameters are 
\begin_inset Formula $\phi_{y}=p(y)$
\end_inset

, 
\begin_inset Formula $\phi_{i|y=1}=p(x_{j}=i|y=1)$
\end_inset

,
\begin_inset Formula $\phi_{i|y=0}=p(x_{j}=i|y=0)$
\end_inset


\end_layout

\begin_layout Standard
The likelihood is then given by 
\end_layout

\begin_layout Standard
\SpecialChar ligaturebreak

\begin_inset Formula 
\[
L(\phi,\phi_{i|y=1},\phi_{i|y=0})=\prod_{i=1}^{m}(\prod_{j=1}^{n_{i}}p(x_{j}^{(i)}|y;\phi_{i|y=1};\phi_{i|y=0}))p(y^{(i)}|\phi).
\]

\end_inset

Maximizing this yield the maximum likelihhod estimates for the parameters:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi_{k|y=1}=\frac{\sum_{i=1}^{m}\sum_{j=1}^{n_{i}}1\{x_{j}^{(i)}=k\land y^{(i)}=1\}}{\sum_{i=1}^{m}1\{y^{(i)}=1\}n_{i}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi_{k|y=0}=\frac{\sum_{i=1}^{m}\sum_{j=1}^{n_{i}}1\{x_{j}^{(i)}=k\land y^{(i)}=0\}}{\sum_{i=1}^{m}1\{y^{(i)}=0\}n_{i}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi_{y}=\frac{\sum_{i=1}^{m}1\{y^{(i)}=1\}}{m}
\]

\end_inset

We can also apply Laplace smoothing (what is needed in practice for good
 performance):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi_{k|y=1}=\frac{\sum_{i=1}^{m}\sum_{j=1}^{n_{i}}1\{x_{j}^{(i)}=k\land y^{(i)}=1\}+1}{\sum_{i=1}^{m}1\{y^{(i)}=1\}n_{i}+|V|}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi_{k|y=0}=\frac{\sum_{i=1}^{m}\sum_{j=1}^{n_{i}}1\{x_{j}^{(i)}=k\land y^{(i)}=0\}+1}{\sum_{i=1}^{m}1\{y^{(i)}=0\}n_{i}+|V|}
\]

\end_inset


\end_layout

\begin_layout Section
Support Vector Machines
\end_layout

\begin_layout Subsection
Margins: Intuition
\end_layout

\begin_layout Standard
Consider logistic regression.
 We would predict 
\begin_inset Quotes eld
\end_inset

1
\begin_inset Quotes erd
\end_inset

 on an input 1 iff 
\begin_inset Formula $h_{\Theta}(x)\ge0.5$
\end_inset

 or equivlently iff 
\begin_inset Formula $\Theta^{T}x\ge0$
\end_inset

.
 The larger 
\begin_inset Formula $\Theta^{T}x$
\end_inset

 is, the higher our degree of 
\begin_inset Quotes eld
\end_inset

confidence
\begin_inset Quotes erd
\end_inset

 that the label is +1+.
 Informally we could also say, that 
\begin_inset Formula $y=1$
\end_inset

 if 
\begin_inset Formula $\Theta^{T}x\gg0$
\end_inset

.
 Similarly we could say that 
\begin_inset Formula $y=0$
\end_inset

 if 
\begin_inset Formula $\Theta^{T}x\ll0$
\end_inset

.
 Therefore we could say informally that we found a good fit if we can find
 
\begin_inset Formula $\Theta$
\end_inset

so that 
\begin_inset Formula $\Theta^{T}x\gg0$
\end_inset

 whenever 
\begin_inset Formula $y^{(i)}=1$
\end_inset

, and 
\begin_inset Formula $\Theta^{T}x\ll0$
\end_inset

 whenever 
\begin_inset Formula $y^{(i)}=0.$
\end_inset


\end_layout

\begin_layout Standard
For another type of intuition, consider the following figure where x's represent
 positive training examples and y's negative training examples.
 The line is also called 
\series bold
separating hyperplane
\series default
.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename margins_intuition.png

\end_inset


\end_layout

\begin_layout Standard
Making a prediction for A should be much easier and more confident than
 one for C.
 It would be nice to have a classifier that allows us to make correct and
 confident predictions on the training examples.
 
\end_layout

\begin_layout Subsection
Notation
\end_layout

\begin_layout Standard
To make things easier we'll consider a linear classifier for a binary classifica
tion problem with labels 
\begin_inset Formula $y\in\{-1,1\}$
\end_inset

.
 We will also use parameters 
\begin_inset Formula $w,b$
\end_inset

 and write our classifier as 
\begin_inset Formula $h_{w,b}(x)=g(w^{T}x+b)$
\end_inset

 where 
\begin_inset Formula $g(z)=1$
\end_inset

if 
\begin_inset Formula $z\ge0$
\end_inset

and 0 otherwise.
 So, 
\begin_inset Formula $b$
\end_inset

 take the role of 
\begin_inset Formula $\Theta_{0}$
\end_inset

and 
\series bold

\begin_inset Formula $w$
\end_inset

 
\series default
the role of 
\begin_inset Formula $[\Theta_{1},\dots,\Theta_{n}]^{T}$
\end_inset

.
\end_layout

\begin_layout Subsection
Functional and geometric margins
\end_layout

\begin_layout Standard
We define the 
\series bold
functional margin
\series default
 of 
\begin_inset Formula $(w,b)$
\end_inset

 with respect to a training example 
\begin_inset Formula $i$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{\gamma}^{(i)}=y^{(i)}(w^{T}x+b)
\]

\end_inset

Note, that when 
\begin_inset Formula $y^{(i)}$
\end_inset

is 1, then for the functional margin to be large, 
\begin_inset Formula $(w^{T}x+b)$
\end_inset

 needs to be a large positive number.
 Similar for 
\begin_inset Formula $y^{(i)}=-1$
\end_inset

it needs to be a large negative number.
 Moreover, if 
\begin_inset Formula $y^{(i)}(w^{T}x+b)>0$
\end_inset

, then our prediction on this example is correct.
 The problem here is that scaling our 
\begin_inset Formula $w,b$
\end_inset

 does not change our hypothesis 
\begin_inset Formula $h_{w,b}$
\end_inset

since it only depends on the sign.
 But scaling affects our functional margin.
 It might make sense to normalize this so we can't exploit this freedom.
 We'll come back later to this.
 For a whole training set 
\begin_inset Formula $S$
\end_inset

 we set the overall function margin to be the smallest of the functional
 margins:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{\gamma}=min\hat{\gamma}^{^{(i)}}
\]

\end_inset

Let's talk about 
\series bold
geometric margins
\series default
.
 Consider the following figure: 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename geometrix_margin.png

\end_inset


\end_layout

\begin_layout Standard
We want to be able to find the value of 
\begin_inset Formula $\gamma^{(i)}$
\end_inset

.
 We know that B is given by 
\begin_inset Formula $x^{(i)}-\gamma^{(i)}\cdot w/||w||$
\end_inset

.
 It also has to satisfy the equation of the decision boundary 
\begin_inset Formula $w^{T}x+b=0$
\end_inset

.
 Hence,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w^{T}\left(x^{(i)}-\gamma^{(i)}\frac{w}{||w||}\right)+b=0
\]

\end_inset

Solving for 
\begin_inset Formula $\gamma^{(i)}$
\end_inset

 yields
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y^{(i)}=\left(\frac{w}{||w||}\right)^{T}x^{(i)}+\frac{b}{||w||}
\]

\end_inset

More generally, to consider negative 
\begin_inset Formula $y$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y^{(i)}=y^{(i)}\left(\left(\frac{w}{||w||}\right)^{T}x^{(i)}+\frac{b}{||w||}\right)
\]

\end_inset

Now scaling 
\begin_inset Formula $w,b$
\end_inset

 does not change the margin.
 Again we define the geometric margin as the smallest of the geometric margins
 of the training set.
 
\end_layout

\begin_layout Subsection
The optimal margin classifier
\end_layout

\begin_layout Standard
It seems that a good way is to find a decision boundary that maximizes the
 margin.
 For this (and now), we'll assume that our data is linear separable.
 This poses the following optimization problem:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
max_{\gamma,w,b}\gamma
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
s.t.\ y^{(i)}(w^{T}x^{(i)}+b)\ge\gamma,\ i=1,\dots,m
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
||w||=1
\]

\end_inset

We want to maximize 
\begin_inset Formula $\gamma$
\end_inset

.
 The last constraint ensures that the functional margin equals the geometric
 margin.
 Solving this problem will result with 
\begin_inset Formula $(w,b)$
\end_inset

 with the largest possible geometric margin.
 This problem is quite hard to solve, so we're going to transform it a bit:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
max_{\gamma,w,b}\frac{\hat{\gamma}}{||w||}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
s.t.\ y^{(i)}(w^{T}x^{(i)}+b)\ge\hat{\gamma},\ i=1,\dots,m
\]

\end_inset

We can do this because of 
\begin_inset Formula $\gamma=\frac{\hat{\gamma}}{||w||}$
\end_inset

.
 This is still a bit nasty, so we keep going with a bit of scaling.
 Since we are now allowed to scale we can set 
\begin_inset Formula $\hat{\gamma}=1$
\end_inset

 and rescale 
\begin_inset Formula $(w,b)$
\end_inset

what leads to:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
min_{\gamma,w,b}\frac{1}{2}||w||^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
s.t.\ y^{(i)}(w^{T}x^{(i)}+b)\ge1,\ i=1,\dots,m
\]

\end_inset

This can be solved efficiently and is called the 
\series bold
optimal margin classifier
\series default
.
 
\end_layout

\begin_layout Subsection
Lagrange duality
\end_layout

\begin_layout Standard
This part is about solving constrained optimization problems.
 Cosnider a problem of the following form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
min_{w}\ f(w)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
s.t.\ h_{i}(w)=0,\ i=1,\dots,l
\]

\end_inset

We now define the 
\series bold
Lagrangian
\series default
 to be
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L(w,\beta)=f(w)+\sum_{i=1}^{l}\beta_{i}h_{i}(w)
\]

\end_inset

The 
\begin_inset Formula $\beta_{i}$
\end_inset

 are called the 
\series bold
Lagrange multipliers
\series default
.
 We would next find and set the partial derivatives of the Langragian to
 zero:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial L}{\partial w_{i}}=0;\ \frac{\partial L}{\partial\beta_{i}}=0
\]

\end_inset

and solve for 
\begin_inset Formula $w$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

.
\end_layout

\begin_layout Standard
We will now generalize this to be also able to solve problems with inequaility
 constraints.
 The following will be called the 
\series bold
primal 
\series default
optimization problem: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
min_{w}\ f(w)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
s.t.\ g_{i}(w)\le0,\ i=1,\dots,k
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
h_{i}(w)=0\ i=1,\dots,l
\]

\end_inset

To solve this we define the 
\series bold
generalized Lagrangian
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L(w,\alpha,\beta)=f(w)+\sum_{i=1}^{k}\alpha_{i}g_{i}(w)+\sum_{i=1}^{l}\beta_{i}h_{i}(w)
\]

\end_inset

 Consider now the quantity
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Theta_{P}(w)=\underset{\alpha,\beta:\alpha_{i}\ge0}{max}L(w,\alpha,\beta)
\]

\end_inset

If, for a given 
\begin_inset Formula $w$
\end_inset

 any of our constraints is hurt, this quanitity will be 
\begin_inset Formula $\infty$
\end_inset

.
 If the constraints are satisfied, then 
\begin_inset Formula $\Theta_{P}(w)=f(w)$
\end_inset

.
 Thus, 
\begin_inset Formula $\Theta_{P}$
\end_inset

takes on the value of our objective if the constraints are satisfied and
 
\begin_inset Formula $\infty$
\end_inset

if they are not satisfied.
 Therefore we can consider the following optimization problem 
\begin_inset Formula 
\[
\underset{w}{min}\Theta_{p}(w)=\underset{w}{min}\underset{\alpha,\beta:\alpha_{i}\ge0}{max}L(w,\alpha,\beta)
\]

\end_inset

and see that it's our original optimization problem.
 We define the optimal value of the objective to be 
\begin_inset Formula $p^{*}=\underset{w}{min}\Theta_{p}(w)$
\end_inset

 and vall this the 
\series bold
value
\series default
 of the primal problem.
 
\end_layout

\begin_layout Standard
Now we look at a different problem.
 We define:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Theta_{D}(\alpha,\beta)=\underset{w}{min}L(w,\alpha,\beta)
\]

\end_inset

Here, the 
\begin_inset Formula $D$
\end_inset

 subscript stands for 
\series bold
dual
\series default
.
 We are now optimizing with respect to 
\begin_inset Formula $w$
\end_inset

, whereas we were optimizing with respect to 
\begin_inset Formula $\alpha,\beta$
\end_inset

 in the primal problem.
 We can now pose the dual optimization problem:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\underset{\alpha,\beta:\alpha_{i}\ge0}{max}\Theta_{D}(w)=\underset{\alpha,\beta:\alpha_{i}\ge0}{max}\underset{w}{min}L(w,\alpha,\beta)
\]

\end_inset

We also define the optimal value of the dual problem's objective to be 
\begin_inset Formula $d^{*}=max_{\alpha,\beta:\alpha_{i}\ge0}\Theta_{D}(w)$
\end_inset

.
 It can easily be show that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
d^{*}=max_{\alpha,\beta:\alpha_{i}\ge0}\Theta_{D}(w)\le min\Theta_{p}(w)=p^{*}
\]

\end_inset

However, under certain conditions we will have 
\begin_inset Formula $d^{*}=p^{*}$
\end_inset

.
 We suppose now that 
\begin_inset Formula $f$
\end_inset

 and the 
\begin_inset Formula $g_{i}$
\end_inset

's are convex and the 
\begin_inset Formula $h_{i}$
\end_inset

's affine (
\begin_inset Formula $h_{i}(w)=a_{i}^{T}w+b)$
\end_inset

, linear with intercept term) and we assume that the constraints on 
\begin_inset Formula $g_{i}$
\end_inset

are feasible.
 Under these assumptions, there must exist 
\begin_inset Formula $w^{*},\alpha^{*},\beta^{*},$
\end_inset

 so that 
\begin_inset Formula $w^{*}$
\end_inset

is the solution to the primal problem and 
\begin_inset Formula $\alpha^{*},\beta^{*}$
\end_inset

are the solution to the dual problem and moreover 
\begin_inset Formula $p^{*}=d^{*}=L(w^{*},\alpha^{*},\beta^{*})$
\end_inset

.
 Also, 
\begin_inset Formula $w^{*},\alpha^{*},\beta^{*}$
\end_inset

satisfy the 
\series bold
Karush-Kuhn-Tucker (KKT) conditions
\series default
, which follow and if they satisfy them, then they're a solution to the
 primal and dual problems:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial w_{i}}L(w^{*},\alpha^{*},\beta^{*})=0,\ i=1,\dots,n
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial\beta_{i}}L(w^{*},\alpha^{*},\beta^{*})=0,\ i=1,\dots,l
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{i}^{*}g_{i}(w^{*})=0,\ i=1,\dots,k
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
g(w^{*})\le0,\ i=1,\dots,k
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha^{*}\ge0,\ i=1,\dots,k
\]

\end_inset


\begin_inset Formula $\alpha_{i}^{*}g(w^{*})=0$
\end_inset

 also means that if 
\begin_inset Formula $\alpha_{i}^{*}>0$
\end_inset

, then 
\begin_inset Formula $g_{i}(w^{*})=0$
\end_inset

.
 We will use this later.
 
\end_layout

\begin_layout Subsection
Optimal margin classifiers
\end_layout

\begin_layout Standard
Remember the primal optimization problem we posed for finding the optimal
 margin classifier:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
min_{\gamma,w,b}\frac{1}{2}||w||^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
s.t.\ y^{(i)}(w^{T}x^{(i)}+b)\ge1,\ i=1,\dots,m
\]

\end_inset

We can write the constraints as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
g_{i}(w)=-y^{(i)}(w^{T}x^{(i)}+b)+1\le0
\]

\end_inset

We have one such constraint per training example.
 Note that from the KKT condition we mentioned, we will have 
\begin_inset Formula $\alpha_{i}>0$
\end_inset

 for only the training examples where the functional margin is exactly 1,
 because only there 
\begin_inset Formula $g_{i}(w)=0$
\end_inset

.
 Look at the figure below
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename svm_figure.png

\end_inset


\end_layout

\begin_layout Standard
You can see exactly three points on the dashed line which signals the points
 where the functional margin is equal to 1.
 The points on these lines (where the 
\begin_inset Formula $\alpha_{i}$
\end_inset

 are non-zero) are called 
\series bold
suport vectors
\series default
.
 
\end_layout

\begin_layout Standard
When we construct the Lagrangian for our optimization problem we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L(w,b,\alpha)=\frac{1}{2}||w||^{2}-\sum_{i=1}^{m}\alpha_{i}[y^{(i)}(w^{T}x^{(i)}+b)-1]
\]

\end_inset

We have only 
\begin_inset Formula $\alpha_{i}$
\end_inset

, but no 
\begin_inset Formula $\beta_{i}$
\end_inset

because we have only inequality constraints.
 Let's find the dual form.
 We start by setting the derivatives of 
\begin_inset Formula $L$
\end_inset

 with respect to 
\series bold

\begin_inset Formula $w,b$
\end_inset

 
\series default
to zero:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nabla_{w}L(w,b,\alpha)=w-\sum_{i=1}^{m}\alpha_{i}y^{(i)}x^{(i)}=0
\]

\end_inset

This implies that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w=\sum_{i=1}^{m}\alpha_{i}y^{(i)}x^{(i)}=0
\]

\end_inset

For the deratives with respect to 
\begin_inset Formula $b$
\end_inset

 we get
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial b}L(w,b,\alpha)=\sum_{i=1}^{m}\alpha_{i}y^{(i)}=0
\]

\end_inset

If we put these back in the Lagrangian, simplify and remember the last result
 we got we obtain
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L(w,b,\alpha)=\sum_{i=1}^{m}\alpha_{i}-\frac{1}{2}\sum_{i,j=1}^{m}y^{(i)}y^{(j)}\alpha_{i}\alpha_{j}(x^{(i)})^{T}x^{(j)}
\]

\end_inset

Putting tis together with the constraint that 
\begin_inset Formula $\alpha_{i}\ge0$
\end_inset

, we get the following dual optimization problem:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
max_{\alpha}W(\alpha)=\sum_{i=1}^{m}\alpha_{i}-\frac{1}{2}\sum_{i,j=1}^{m}y^{(i)}y^{(j)}\alpha_{i}\alpha_{j}(x^{(i)})^{T}x^{(j)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
s.t.\ \alpha_{i}\ge0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{i=0}^{m}\alpha_{i}y^{(i)}=0
\]

\end_inset

The KKT conditions are all satisfied.
 We'll talk later about how to get the optimal values for the 
\begin_inset Formula $\alpha_{i}$
\end_inset

.
 But if we had them we could solve for the optimal 
\begin_inset Formula $w$
\end_inset

 and then, having this solve for the optimal value of the intercept b, that
 would be
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
b^{*}=-\frac{max_{i:y^{(i)}=-1}w^{*T}x^{(i)}+min_{i:y^{(i)}=1}w^{*T}x^{(i)}}{2}
\]

\end_inset

Before we finish here we look at how we could make a prediction.
 Having fit the parameters, we would calculate 
\begin_inset Formula $w^{T}x+b$
\end_inset

 and predict 
\begin_inset Formula $y=1$
\end_inset

iff it is bigger than 0.
 This quantity can also be written as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w^{T}x+b=\sum_{i=1}^{m}\alpha_{i}y^{(i)}<x^{(i)},x>+b
\]

\end_inset

where all but the suport vectors are zero.
 This will help making this algorithm fast and efficient.
 
\end_layout

\begin_layout Subsection
Kernels
\end_layout

\begin_layout Standard
In the beginning we had our example where we had the living area as input
 
\begin_inset Formula $x$
\end_inset

.
 We then considered using the features 
\begin_inset Formula $x,x^{2},x^{3}$
\end_inset

and some cubic form.
 To be able to distinguish we will further call the original input value
 the 
\series bold
input attributes
\series default
 of a problem.
 When they get somewhat mapped (could also just be 1:1) and then used in
 our learning algorithm we'll call those 
\series bold
input features
\series default
.
 We also denote 
\begin_inset Formula $\phi$
\end_inset

the 
\series bold
feature mapping
\series default
, which maps from the attributes to the features.
 In the mentioned example we had:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi(x)=\left[\begin{array}{c}
x\\
x^{2}\\
x^{3}
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
In our SVM, we may want to work with such mapped features.
 To do so we can simply use 
\begin_inset Formula $\phi(x)$
\end_inset

 instead of 
\begin_inset Formula $x$
\end_inset

.
 Since the algorithm has been written in terms of inner products 
\begin_inset Formula $<x,z>$
\end_inset

 we would replace these with 
\begin_inset Formula $<\phi(x),\phi(z)>$
\end_inset

.
 Given a feature mapping 
\begin_inset Formula $\phi$
\end_inset

, we fedine the corresponding 
\series bold
Kernel
\series default
 to be 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
K(x,z)=\phi(x)^{T}\phi(z)
\]

\end_inset

Then, everywhere we had 
\begin_inset Formula $<x,z>$
\end_inset

in our algorithm we replace it with 
\begin_inset Formula $K(x,z)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Now, given 
\begin_inset Formula $\phi$
\end_inset

we could easily compute 
\begin_inset Formula $K(x,z)$
\end_inset

 by finding 
\begin_inset Formula $\phi(x)$
\end_inset

 and 
\begin_inset Formula $\phi(z)$
\end_inset

 and taking their inner product.
 But more interesting is that often, 
\begin_inset Formula $K(x,z)$
\end_inset

 may be very inexpensive to calculate even though 
\begin_inset Formula $\phi(x)$
\end_inset

 may be very expensive (e.g.
 because it's high-dimensional).
 By using an efficient way to calculate 
\begin_inset Formula $K(x,z)$
\end_inset

 in our algorithm, we can get the SVMs to learn in high dimensional feature
 space given by 
\begin_inset Formula $\phi$
\end_inset

without ever having to explicitly use 
\begin_inset Formula $\phi(x)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Let's see an example.
 Suppose 
\begin_inset Formula $x,z\in\mathbb{R}^{n}$
\end_inset

and consider 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
K(x,z)=(x^{T}z)^{2}
\]

\end_inset

We can also write this as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
K(x,z)=\sum_{i,j=1}^{n}(x_{i}x_{j})(z_{i}z_{j})
\]

\end_inset

Only calculating 
\begin_inset Formula $\phi(x)$
\end_inset

, here in the case of 
\begin_inset Formula $n=2$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\phi(x)=\left[\begin{array}{c}
x_{1}x_{1}\\
x_{1}x_{2}\\
x_{2}x_{1}\\
x_{2}x_{2}
\end{array}\right]
\]

\end_inset

Whereas calculating 
\begin_inset Formula $K(x,z)$
\end_inset

 only required 
\begin_inset Formula $O(n)$
\end_inset

 time, just calculating 
\begin_inset Formula $\phi(x)$
\end_inset

 took 
\begin_inset Formula $O(n^{2})$
\end_inset

 time.
 Even though we mapped to a higher dimensional space, we can still work
 in linear time.
 
\end_layout

\begin_layout Standard
Now, let's talk about a different, intuitive view of kernels.
 Intuitively we might expect 
\begin_inset Formula $K(x,z)$
\end_inset

 to be large when 
\begin_inset Formula $\phi(x)$
\end_inset

 and 
\begin_inset Formula $\phi(z)$
\end_inset

 are close together (because the angle in between is small) and small when
 they are far apart.
 So we can think of the kernel 
\begin_inset Formula $K(x,z)$
\end_inset

 as a measurment of how similar 
\begin_inset Formula $\phi(x)$
\end_inset

 and 
\begin_inset Formula $\phi(z)$
\end_inset

 are.
 Given this intuition we might choose 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
K(x,z)=exp\left(-\frac{||x-z||^{2}}{2\sigma^{2}}\right).
\]

\end_inset

 This kernel is called the 
\series bold
Gaussian kernel
\series default
 and is a valid kernel.
 But how can we generally decide if a kernel is valid?
\end_layout

\begin_layout Standard
We denote the 
\series bold
Kernel matrix
\series default
 to be the matrix defined by 
\begin_inset Formula $K_{ij}=K(x^{(i)},x^{(j)})$
\end_inset

 where the 
\begin_inset Formula $x^{(i)}$
\end_inset

come from a set of points.
 Now, 
\begin_inset Formula $K$
\end_inset

 is a valid kernel if and only if its matrix is 
\emph on
positive semi-definite
\emph default
.
 
\end_layout

\begin_layout Standard
Shortly: Kernels let you work efficiently in high dimensional space.
 
\end_layout

\begin_layout Subsection
Regularization and the non-seperable case
\end_layout

\begin_layout Standard
So far, we've only worked in cases where the data was linearly seperable.
 But this might not be the case or you could also just have small outliners
 that change your hyperplane dramatically to the worse (see figure) 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename outliner_hyperplane.png

\end_inset


\end_layout

\begin_layout Standard
To make the algorithm work for non-linearly seperable datasets as well as
 be less sensitive to such outliners, we reformulate our optimization using
 
\begin_inset Formula $l_{1}$
\end_inset


\series bold
-regularization
\series default
:
\begin_inset Formula 
\[
min_{\gamma,w,b}\frac{1}{2}||w||^{2}+C\sum_{i=1}^{m}\xi_{i}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
s.t.\ y^{(i)}(w^{T}x^{(i)}+b)\ge1-\xi_{i},\ i=1,\dots,m
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\xi_{i}\ge0\ i=1,\dots,m
\]

\end_inset

Examples are now allowed to have a functional margin less than 1, and if
 an example has such a functional margin 
\begin_inset Formula $1-\xi_{i}$
\end_inset

, we would pay a cost to our objective function being increased with 
\begin_inset Formula $C\xi_{i}$
\end_inset

.
 
\begin_inset Formula $C$
\end_inset

 controls the relative weighting between the two goals of keeping the objective
 function small and ensuring most examples have a functional margin of at
 least 1.
 
\end_layout

\begin_layout Standard
We can again form the Lagrangian:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L(w,b,\alpha)=\frac{1}{2}||w||^{2}+C\sum_{i=1}^{m}\xi_{i}-\sum_{i=1}^{m}\alpha_{i}[y^{(i)}(w^{T}x^{(i)}+b)-1+\xi_{i}]-\sum_{i=1}^{m}r_{i}\xi_{i}
\]

\end_inset

The 
\begin_inset Formula $\alpha_{i}$
\end_inset

's and 
\begin_inset Formula $r_{i}$
\end_inset

's are our Lagrange multipliers (
\begin_inset Formula $\ge0$
\end_inset

).
 We then obtain the dual form of the problem:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
max_{\alpha}W(\alpha)=\sum_{i=1}^{m}\alpha_{i}-\frac{1}{2}\sum_{i,j=1}^{m}y^{(i)}y^{(j)}\alpha_{i}\alpha_{j}(x^{(i)})^{T}x^{(j)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
s.t.\ 0\le\alpha_{i}\le C
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{i=0}^{m}\alpha_{i}y^{(i)}=0
\]

\end_inset

Applying the 
\begin_inset Formula $l_{1}$
\end_inset

-regulariztation, the only change here is that the 
\begin_inset Formula $\alpha_{i}$
\end_inset

also have to be less or equal to 
\begin_inset Formula $C$
\end_inset

.
 Also, the KKT dual-complementarity conditions are:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{i}=0\Rightarrow y^{(i)}(w^{T}x^{(i)}+b)\ge1
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{i}=C\Rightarrow y^{(i)}(w^{T}x^{(i)}+b)\le1
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
0<\alpha_{i}<C\Rightarrow y^{(i)}(w^{T}x^{(i)}+b)=1
\]

\end_inset


\end_layout

\begin_layout Subsection
The SMO algorithm
\end_layout

\begin_layout Standard
The 
\series bold
sequential minimal algorithm SMO
\series default
 gives an efficient way of solvinf the dual problem in SVMs.
 
\end_layout

\begin_layout Subsubsection
Coordinate ascent
\end_layout

\begin_layout Standard
Consider trying to solve the unconstrained optimization problem
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\underset{\alpha}{max}W(\alpha_{1},\dots,\alpha_{m})
\]

\end_inset

Here we think of 
\begin_inset Formula $W$
\end_inset

 as some funciton of the parameters 
\begin_inset Formula $\alpha_{i}$
\end_inset

and ignore every ressemblance or similarity.
 We're going to consider a new algorithm called 
\series bold
coordinate ascent
\series default
: 
\end_layout

\begin_layout Standard
Loop until convergence: {
\end_layout

\begin_layout Standard
\begin_inset Formula $\qquad$
\end_inset

For 
\begin_inset Formula $i=1,\dots,m$
\end_inset

{
\end_layout

\begin_layout Standard
\begin_inset Formula $\qquad\qquad\alpha_{i}:=arg\,max_{\hat{\alpha_{i}}}W(\alpha_{1},\dots,\alpha_{i-1},\hat{\alpha}_{i},\alpha_{i+1},\dots,\alpha_{m})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\qquad$
\end_inset

}
\end_layout

\begin_layout Standard
}
\end_layout

\begin_layout Standard
Thus, for each loop we hold all except 
\begin_inset Formula $\alpha_{i}$
\end_inset

 fixed and reoptimize 
\begin_inset Formula $W$
\end_inset

 with respect to just the parameter 
\begin_inset Formula $\alpha_{i}$
\end_inset

.
 The order in which we choose the 
\begin_inset Formula $\alpha$
\end_inset

to be optimized can be to our likings (e.g.
 the one we expect the largest increase for 
\begin_inset Formula $W(\alpha)$
\end_inset

).
 When the innermost 
\begin_inset Formula $arg\,max$
\end_inset

 can be calculated efficiently, coordinate ascent can be fairly efficient.
 Following is a figure of some coordinate ascent example:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename coordinate_ascent.png

\end_inset


\end_layout

\begin_layout Subsubsection
SMO
\end_layout

\begin_layout Standard
Again, this is the dual optimization problem we want to solve:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
max_{\alpha}W(\alpha)=\sum_{i=1}^{m}\alpha_{i}-\frac{1}{2}\sum_{i,j=1}^{m}y^{(i)}y^{(j)}\alpha_{i}\alpha_{j}(x^{(i)})^{T}x^{(j)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
s.t.\ 0\le\alpha_{i}\le C
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{i=0}^{m}\alpha_{i}y^{(i)}=0
\]

\end_inset

Assume we have a set of 
\begin_inset Formula $\alpha_{i}$
\end_inset

 that satisfy this constraint.
 When we want to update some objects of the 
\begin_inset Formula $\alpha_{i}$
\end_inset

, we have to update at least two of them simultaneously to keep satisfying
 the constraint.
 We will do the following in the SMO:
\end_layout

\begin_layout Standard
Repeat till convergence {
\end_layout

\begin_layout Enumerate
Select some pair 
\begin_inset Formula $\alpha_{i}$
\end_inset

and 
\begin_inset Formula $\alpha_{j}$
\end_inset

 to update next (using a heuristic that picks the two that will allow us
 to make the biggest progress)
\end_layout

\begin_layout Enumerate
Reoptimize 
\begin_inset Formula $W(\alpha)$
\end_inset

 with respect to 
\begin_inset Formula $\alpha_{i}$
\end_inset

and 
\begin_inset Formula $\alpha_{j}$
\end_inset

 while holding all other 
\begin_inset Formula $\alpha_{k}$
\end_inset

 fixed.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $\quad$
\end_inset

}
\end_layout

\begin_layout Standard
To check for convergence we can check whether the KKT conditions are satisfied
 within some tolerance convergence parameter 
\begin_inset Formula $tol$
\end_inset

 which is typically set around 0.001 to 0.01.
\end_layout

\begin_layout Standard
The key to efficency is to be able to compute the update efficiently.
 Let's shortly sketch this update: 
\end_layout

\begin_layout Standard
Let's say in our current step we want to optimize 
\begin_inset Formula $\alpha_{1},\alpha_{2}$
\end_inset

.
 We hold all other fixed and we know that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{1}y^{(1)}+\alpha_{2}y^{(2)}=-\sum_{i=3}^{m}\alpha_{i}y^{(i)}
\]

\end_inset

The right side is fixed so we can denote it by some constant 
\begin_inset Formula $\zeta$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{1}y^{(1)}+\alpha_{2}y^{(2)}=\zeta
\]

\end_inset

We can picture the constraints as follows:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename smo.png

\end_inset


\end_layout

\begin_layout Standard
From the constraints, we know that 
\begin_inset Formula $\alpha_{1}$
\end_inset

and 
\begin_inset Formula $\alpha_{2}$
\end_inset

must lie within the box [0,
\begin_inset Formula $C$
\end_inset

] x [0,
\begin_inset Formula $C$
\end_inset

].
 Also we know that they both must lie on the line plotted.
 We rewrite our equation a bit:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{1}=(\zeta-\alpha_{2}y^{(2)})y^{(1)}
\]

\end_inset

Hence, the objective function can be written as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
W(\alpha_{1},\dots,\alpha_{m})=W((\zeta-\alpha_{2}y^{(2)})y^{(1)},\alpha_{2},\dots,\alpha_{m})
\]

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
This is just some quadratic function in 
\begin_inset Formula $\alpha_{2}$
\end_inset

, so we can express it as 
\begin_inset Formula $a\alpha_{2}^{2}+b\alpha_{2}+c$
\end_inset

 for some appropriate a,b and c.
 We can easily calculate the maximum value for this and denote it as 
\begin_inset Formula $\alpha_{2}^{new,unclipped}$
\end_inset

uf we ignore the box constraint.
 Now we just have to make sure it lies within the minimum and maximum it
 may take (clip inside the [L,H] interval):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{2}^{new}=\begin{cases}
\begin{array}{c}
H\\
\alpha_{2}^{new,unclipped}\\
L
\end{array} & \begin{array}{c}
if\ \alpha_{2}^{new,unclipped}>H\\
if\ L\le\alpha_{2}^{new,unclipped}\le H\\
if\ \alpha_{2}^{new,unclipped}<L
\end{array}\end{cases}
\]

\end_inset

Having this we can just plug it back into our equation and solve for 
\begin_inset Formula $\alpha_{1}^{new}$
\end_inset

.
\end_layout

\begin_layout Section
Learning Theory
\end_layout

\begin_layout Subsection
Bias/variance tradeoff
\end_layout

\begin_layout Standard
Using linear regression, we might think about whether to use 
\begin_inset Quotes eld
\end_inset

simple
\begin_inset Quotes erd
\end_inset

 model like a linear one or more complex like the polynomial one.
 Consider the following example:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename bias_variance.png

\end_inset


\end_layout

\begin_layout Standard
Fitting a 5th order polynomial does not result in a good model.
 Even though it would do very well on predicting training example it would
 do a bad job on new examples.
 It 
\series bold
generalizes
\series default
 badly.
 The 
\series bold
generalization error
\series default
 of a hypothesis is its expected error on examples not necessarily in the
 training set.
 Informally, we define the 
\series bold
bias
\series default
 of a model to be the expected generalization error, even if we fit it to
 a huge training set.
 Thus, in the problem above, the linear model suffers from large bias and
 may underfit the data.
 
\end_layout

\begin_layout Standard
The second component to the generalization error, consisting of the 
\series bold
variance 
\series default
of a model fitting procedure.
 Especially, when fitting high-order polynomial like the right-most figure,
 there is a large risk that we're fitting patterns in the data that happen
 to be only present in our training examples but do not reflect the relationship
 between 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $y$
\end_inset

.
 By fitting these patterns we might again obtain a model with large generalizati
on error.
 In this case, we would say the model has large variance.
 
\end_layout

\begin_layout Standard
Often, there is a tradeoff between bias and variance.
 If our model has too few parameters, it may have large bias and small variance,
 but if it has too many parameters, it may have small bias and large variance.
 In the figures above, the quadratic function does best in predicting new
 examples.
 
\end_layout

\begin_layout Subsection
Preliminaries
\end_layout

\begin_layout Standard
This chapter will help us hone our intuition and derive rules of thumb about
 how to best apply learning algorithms in different settings.
 We will also try to formalize the bias/variance tradeoff and answer other
 questions.
 
\begin_inset Newline newline
\end_inset


\series bold
Lemma.

\series default
 Let 
\begin_inset Formula $A_{1},\dots,A_{k}$
\end_inset

 be 
\begin_inset Formula $k$
\end_inset

 different events (that may not be independent).
 Then
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(A_{1}\cup\dots\cup A_{k})\le P(A_{1})+\dots+P(A_{k}).
\]

\end_inset


\series bold
Lemma.

\series default
 Let 
\begin_inset Formula $Z_{1},\dots,Z_{m}$
\end_inset

 be 
\begin_inset Formula $m$
\end_inset

 independent and iid random variables drawn from a Bernoulli(
\begin_inset Formula $\phi$
\end_inset

) distribution.
 I.e.
 
\begin_inset Formula $P(Z_{i}=1)=\phi$
\end_inset

 and 
\begin_inset Formula $P(Z_{i}=1-\phi)$
\end_inset

.
 Let 
\begin_inset Formula $\hat{\phi}=(1/m)\sum_{i=1}^{m}Z_{i}$
\end_inset

 be the mean of these random variables and let any 
\begin_inset Formula $\gamma>0$
\end_inset

 be fixed.
 Then
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(|\phi-\hat{\phi}|>\gamma)\le2exp(-2\gamma^{2}m)
\]

\end_inset

 This lemma (which is also called the 
\series bold
Chernoff bound
\series default
) says that if we take 
\begin_inset Formula $\hat{\phi}$
\end_inset

-the average of 
\begin_inset Formula $m$
\end_inset

 Bernoulli(
\begin_inset Formula $\phi)$
\end_inset

 random variables- to be our estimate of 
\begin_inset Formula $\phi$
\end_inset

, then the probability of being far from the true value is small, so long
 as 
\begin_inset Formula $m$
\end_inset

 is large.
 You can also say that if you have a biased coin which has a chance of 
\begin_inset Formula $\phi$
\end_inset

for heads and you toss it 
\begin_inset Formula $m$
\end_inset

 times and calculate the fraction of times it came up heads, tat will be
 a good estimate of 
\begin_inset Formula $\phi$
\end_inset

(as long as 
\begin_inset Formula $m$
\end_inset

 is large).
 
\end_layout

\begin_layout Standard
We will stick to binary classification in which the labels are 
\begin_inset Formula $y\in\{0,1\}$
\end_inset

.
 All our conclusions can be generalized.
 
\end_layout

\begin_layout Standard
We assume that we are given a training set 
\begin_inset Formula $S$
\end_inset

 of size 
\begin_inset Formula $m$
\end_inset

, where the training examples 
\begin_inset Formula $(x^{(i)},y^{(i)})$
\end_inset

 are drawn iid from some probability distribution 
\begin_inset Formula $D.$
\end_inset

 For a hypothesis 
\begin_inset Formula $h$
\end_inset

 we define the 
\series bold
training error 
\series default
(also called 
\series bold
emiprical risk 
\series default
or 
\series bold
empirical error
\series default
) to be
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{\hat{\epsilon}(h)=\frac{1}{m}\sum_{i=1}^{m}1\{h(x^{(i)}\ne y^{(i)}\}}
\]

\end_inset

If we want to make the dependence of the training set clear we can also
 write 
\begin_inset Formula $\hat{\epsilon}_{S}(h)$
\end_inset

.
 We also define the generalization error to be
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\epsilon(h)=P_{(x,y)\sim D}(h(x)\ne y).
\]

\end_inset

This is the probability that, if we now draw a new example from a distribution
 
\begin_inset Formula $D$
\end_inset

, we will misclassify it.
 Note that we assume that all our training data is drawn from the same distribut
ion 
\begin_inset Formula $D$
\end_inset

.
 
\end_layout

\begin_layout Standard
Consider the setting of linear classification and let 
\begin_inset Formula $h_{\Theta}(x)=\text{1\{\Theta}^{T}x\}$
\end_inset

.
 A way to fit the parameters 
\begin_inset Formula $\Theta$
\end_inset

is to mimimize the training error and pick
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{\Theta}=arg\ min_{\Theta}\hat{\epsilon}(h_{\Theta})
\]

\end_inset

We call this the 
\series bold
empirical risk minimization ERM
\series default
 and the resulting hypothesis output by the learning algorithm is 
\begin_inset Formula $\hat{h}=h_{\hat{\Theta}}$
\end_inset

.
 
\end_layout

\begin_layout Standard
We will further abstract away from specific parameterization of hypotheses
 and from wether we're using a linear classifier.
 We define the 
\series bold
hypothesis class
\series default
 
\begin_inset Formula $H$
\end_inset

 used by a learning algorithm to be the set of all classifiers considered
 by it.
 For linear classification 
\begin_inset Formula $H=\{h_{\Theta}:h_{\Theta}(x)=1\{\Theta^{T}x\},\Theta\in\mathbb{R}^{n+1}\}$
\end_inset

is the set of all classifiers over the domain of inputs 
\begin_inset Formula $X$
\end_inset

 where the decision boundary is linear.
 If we were looking at, say, neural networks then we could let 
\begin_inset Formula $H$
\end_inset

 be the set of all classifiers representable by some neural network architecture.
 
\end_layout

\begin_layout Standard
Empirical risk minimization can now be thought as the minimization over
 the class of functions 
\begin_inset Formula $H$
\end_inset

, in which the learning algorithm picks the hypothesis
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{h}=arg\ \underset{h\in H}{min}\hat{\epsilon}(h)
\]

\end_inset


\end_layout

\begin_layout Subsection
The case of finite 
\begin_inset Formula $H$
\end_inset


\end_layout

\begin_layout Standard
We consider now a learning problem in which we have a finite hypothesis
 class 
\begin_inset Formula $H=\{h_{1},\dots h_{k}\}$
\end_inset

 consisting of 
\begin_inset Formula $k$
\end_inset

 hypotheses.
 Thus, 
\begin_inset Formula $H$
\end_inset

 is a set of functions mapping from 
\begin_inset Formula $X$
\end_inset

 to 
\begin_inset Formula $\{0,1\}$
\end_inset

 and empirical risk minimization picks the one with the smallest error.
 To be able to give a guarrantee on the generalization error by first showing
 that 
\begin_inset Formula $\hat{\epsilon}(h)$
\end_inset

 is a reliable estate of 
\begin_inset Formula $\epsilon(h)$
\end_inset

 for all hypotheses 
\begin_inset Formula $h$
\end_inset

 and second showing that this implies an upper bound on the generalization
 error on 
\begin_inset Formula $\hat{h}.$
\end_inset


\end_layout

\begin_layout Standard
Take any fixed 
\begin_inset Formula $h_{i}\in H$
\end_inset

.
 Consider a random variable 
\begin_inset Formula $Z$
\end_inset

: We're going to sample 
\begin_inset Formula $(x,y)\sim D.$
\end_inset

 Then we set 
\begin_inset Formula $Z=1\{h_{i}(x)\ne y\}$
\end_inset

.
 In other words, Z indicates whether 
\begin_inset Formula $h_{i}$
\end_inset

 misclassifies it.
 We also define 
\begin_inset Formula $Z_{j}=1\{h_{i}(x^{(j)}\ne y^{(j)}\}$
\end_inset

.
 
\end_layout

\begin_layout Standard
The misclassification probability on a randomy drawn example (
\begin_inset Formula $\epsilon(h)$
\end_inset

) is exactly the expected value of 
\begin_inset Formula $Z$
\end_inset

 .
 Moreover, the training error can be written as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{\epsilon}(h_{i})=\frac{1}{m}\sum_{j=1}^{m}Z_{j}
\]

\end_inset

Thus, 
\begin_inset Formula $\hat{\epsilon}$
\end_inset

 is exactly the mean of the 
\begin_inset Formula $m$
\end_inset

 random variables 
\begin_inset Formula $Z_{j}$
\end_inset

 that are drawn iid from a Bernoulli distribution with mean 
\begin_inset Formula $\epsilon(h_{i})$
\end_inset

.
 Applying the heffding inequality, we obtain
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(|\epsilon(h_{i})-\hat{\epsilon}(h_{i})|>\gamma)\le2exp(-2\gamma^{2}m)
\]

\end_inset

This shows that 
\begin_inset Formula $\epsilon(h_{i})$
\end_inset

 will be close to 
\begin_inset Formula $\hat{\epsilon}(h_{i})$
\end_inset

.
 We want to show that this is true for all hypotheses.
 Let 
\begin_inset Formula $A_{i}$
\end_inset

denote the event that 
\begin_inset Formula $|\epsilon(h_{i})-\hat{\epsilon}(h_{i})|>\gamma$
\end_inset

.
 Through the union bond lemma and the equation above, we get that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(\lnot\exists h\in H:\,|\,\epsilon(h_{i})-\hat{\epsilon}(h_{i})|>\gamma)=1-2k\,exp(-2\gamma^{2}m)
\]

\end_inset

What we did was, for particular values of 
\begin_inset Formula $m$
\end_inset

 and 
\begin_inset Formula $\gamma$
\end_inset

.
 , given a bound on probability that 
\begin_inset Formula $|\epsilon(h)-\hat{\epsilon}(h)|>\gamma$
\end_inset

.
 Now, given 
\begin_inset Formula $\gamma$
\end_inset

 and some 
\begin_inset Formula $\delta>0$
\end_inset

, how large must 
\begin_inset Formula $m$
\end_inset

 be before we can guarantee that with probability of at least 
\begin_inset Formula $1-\delta$
\end_inset

, training error will be within 
\begin_inset Formula $\gamma$
\end_inset

of generalization error? By setting 
\begin_inset Formula $\delta=2k\,exp(-2\gamma^{2}m)$
\end_inset

 and solving for 
\begin_inset Formula $m$
\end_inset

 we get that if
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
m\ge\frac{1}{2\gamma^{2}}log\frac{2k}{\delta},
\]

\end_inset

 then with probabilty of at least 
\begin_inset Formula $1-\delta$
\end_inset

, we have that 
\begin_inset Formula $|\epsilon(h)-\hat{\epsilon}(h)|\le\gamma$
\end_inset

 for all hypotheses (or that the probability of the difference of the errors
 being greater than 
\begin_inset Formula $\gamma$
\end_inset

 is at most 
\begin_inset Formula $\delta$
\end_inset

).
 The training set size 
\begin_inset Formula $m$
\end_inset

 that a certain method or algorithm requires to achieve a certain level
 of performance is also called the algorithm's 
\series bold
sample complexity
\series default
.
 
\end_layout

\begin_layout Standard
Similarly, we can also hold 
\begin_inset Formula $m$
\end_inset

 and 
\begin_inset Formula $\delta$
\end_inset

 fixed and show that with probability 
\begin_inset Formula $1-\delta$
\end_inset

, we have that for all hypotheses
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
|\epsilon(h)-\hat{\epsilon}(h)|\le\sqrt{\frac{1}{2m}log\frac{2k}{\delta}}.
\]

\end_inset

 We assume now that uniform convergence holds and define 
\begin_inset Formula $h^{*}=arg\,min_{h\in H}\hat{\epsilon}(h)$
\end_inset

 to be the best possible hypothesis in 
\begin_inset Formula $H$
\end_inset

.
 It makes sense to compare with 
\begin_inset Formula $h^{*}$
\end_inset

since this is the best possible hypothesis.
 Pick 
\begin_inset Formula $\hat{h}=arg\,min_{h\in H}\hat{\epsilon}(h)$
\end_inset

.
 We have now:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\epsilon(\hat{h})\le\epsilon(h^{*})+2\gamma
\]

\end_inset


\series bold
Theorem.

\series default
 Let 
\begin_inset Formula $|H|=k$
\end_inset

 and any 
\begin_inset Formula $m,\delta$
\end_inset

 be fixed.
 Then with probability of at least 
\begin_inset Formula $1-\delta$
\end_inset

, we have that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\epsilon(\hat{h})\le\left(\underset{h\in H}{min}\epsilon(h)\right)+2\sqrt{\frac{1}{2m}log\frac{2k}{\delta}}
\]

\end_inset

Note, that this also quantifies our statement about bias/variance.
 If we switch from our hypothesis class 
\begin_inset Formula $H$
\end_inset

 to a bigger class 
\begin_inset Formula $H'$
\end_inset

with 
\begin_inset Formula $H'\supseteq H$
\end_inset

, then our first term (the bias) decreases (because we're taking the min
 from more hypotheses), but the second term (the variance) increases (because
 
\begin_inset Formula $k$
\end_inset

 gets bigger).
 
\end_layout

\begin_layout Standard
By holding 
\begin_inset Formula $\gamma$
\end_inset

 and 
\begin_inset Formula $\delta$
\end_inset

fixed and solving for m, we can also obtain the complexity bound: 
\begin_inset Newline newline
\end_inset


\series bold
Corollary.

\series default
 Let 
\begin_inset Formula $|H|=k$
\end_inset

 and let any 
\begin_inset Formula $\delta,\gamma$
\end_inset

 be fiexed.
 Then for 
\begin_inset Formula $\epsilon(\hat{h})\le min_{h\in H}\epsilon(h)+2\gamma$
\end_inset

 to hold with probability at least 
\begin_inset Formula $1-\delta$
\end_inset

, it suffices that 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
m\ge O\left(\frac{1}{\gamma^{2}}log\frac{k}{\delta}\right)
\]

\end_inset


\end_layout

\begin_layout Subsection
The case of inifinite 
\begin_inset Formula $H$
\end_inset


\end_layout

\begin_layout Standard
Many hypothesis classes actually contain an infinite number of functions.
 Suppose now, that we have an 
\begin_inset Formula $H$
\end_inset

, that is parameterized by 
\begin_inset Formula $d$
\end_inset

 real numbers.
 We'd be using 64 bit to represent a float and this means our learning algorithm
 is parameterized by 
\begin_inset Formula $64d$
\end_inset

 bits.
 Thus our hypothesis class consists at most 
\begin_inset Formula $k=2^{64d}$
\end_inset

different hypotheses.
 To guarantee that 
\begin_inset Formula $\epsilon(\hat{h})\le\epsilon(h^{*})+2\gamma$
\end_inset

 to hold with probability at least 
\begin_inset Formula $1-\delta,$
\end_inset

 it suffices that 
\begin_inset Formula $m=O_{\gamma,\delta}(d)$
\end_inset

 (linear, parameterized by 
\begin_inset Formula $\gamma$
\end_inset

 and 
\begin_inset Formula $\delta$
\end_inset

).
 This means to do well we're going to need on the order of a linear number
 of training examples in
\begin_inset Formula $d$
\end_inset

.
 
\end_layout

\begin_layout Standard
To derive a more satisfying argument, we need more definitions.
 
\end_layout

\begin_layout Standard
Given a set 
\begin_inset Formula $S=\{x^{(i)},\dots,x^{(d)}\}$
\end_inset

 (no relation to the training set) of points 
\begin_inset Formula $x^{(i)}\in X$
\end_inset

, we say that 
\begin_inset Formula $H$
\end_inset

 
\series bold
shatters
\series default
 S, if 
\begin_inset Formula $H$
\end_inset

 can realize any labeling on S.
 I.e.
 if for any set of labels 
\begin_inset Formula $\{y^{(1)},\dots,y^{(d)}\}$
\end_inset

, there exists some 
\begin_inset Formula $h\in H$
\end_inset

 so that 
\begin_inset Formula $h(x^{(i)})=y^{(i)}$
\end_inset

for all 
\begin_inset Formula $i=1,\dots,d$
\end_inset

.
 
\end_layout

\begin_layout Standard
Given a hypothesis class 
\begin_inset Formula $H$
\end_inset

, we then define its 
\series bold
Vapnik-Chervonenkis dimension VC(
\begin_inset Formula $H$
\end_inset

)
\series default
, to be the size of the largest set that is shattered by H.
 
\end_layout

\begin_layout Standard
For instance, consider the following figure:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename VC.png

\end_inset


\end_layout

\begin_layout Standard
Can the set 
\begin_inset Formula $H$
\end_inset

 of linear classifiers in two dimensions (
\begin_inset Formula $h(x)=1\{\Theta_{0}+\Theta_{1}x_{1}+\Theta_{2}x_{2}\ge0\}$
\end_inset

) shatter the set above? Yes, it can:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename VC_linear.png

\end_inset


\end_layout

\begin_layout Standard
But it is possible to show that there is no set of 4 points that this hypothesis
 class can shatter.
 Thus, VC(
\begin_inset Formula $H$
\end_inset

)=3.
 
\end_layout

\begin_layout Standard
To prove that VC(
\begin_inset Formula $H$
\end_inset

) is at least 
\begin_inset Formula $d$
\end_inset

, we need to show that there's at least 
\emph on
one
\emph default
 set of size 
\begin_inset Formula $d$
\end_inset

 that 
\begin_inset Formula $H$
\end_inset

 can shatter.
 
\begin_inset Newline newline
\end_inset


\series bold
Theorem.
 
\series default
Let 
\begin_inset Formula $H$
\end_inset

 be given, and let 
\begin_inset Formula $d=VC(H)$
\end_inset

, Then with probability at least 
\begin_inset Formula $1-\delta$
\end_inset

, we have that for all 
\begin_inset Formula $h\in H$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
|\epsilon(h)-\hat{\epsilon}(h)|\le O\left(\sqrt{\frac{d}{m}log\frac{m}{d}+\frac{1}{m}log\frac{1}{\delta}}\right)
\]

\end_inset

And
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
|\epsilon(\hat{h})\le\epsilon(h^{*})+O\left(\sqrt{\frac{d}{m}log\frac{m}{d}+\frac{1}{m}log\frac{1}{\delta}}\right).
\]

\end_inset

In other words, if a hypothesis class has finite VC dimension, then the
 uniform convergence occurs as 
\begin_inset Formula $m$
\end_inset

 becomes large.
\begin_inset Newline linebreak
\end_inset


\series bold
Corollary.
 
\series default
For 
\begin_inset Formula $|\epsilon(h)-\hat{\epsilon}(h)|\le\gamma$
\end_inset

 to hold for all hypotheses with probability at least 
\begin_inset Formula $1-\delta$
\end_inset

, it suffices that 
\begin_inset Formula $m=O_{\gamma,\delta}(d)$
\end_inset

.
 
\end_layout

\begin_layout Standard
In other words, the number of training examples to learn 
\begin_inset Quotes eld
\end_inset

well
\begin_inset Quotes erd
\end_inset

 using 
\begin_inset Formula $H$
\end_inset

 ist linear in the VC dimension of 
\begin_inset Formula $H$
\end_inset

.
 It also turns out, that for 
\begin_inset Quotes eld
\end_inset

most
\begin_inset Quotes erd
\end_inset

 hypothesis classes, the VC dimension is also roughly linear in the number
 of parameters.
 So, the number of training examples needed is usually roughly linear in
 the number of parameters of 
\begin_inset Formula $H.$
\end_inset


\end_layout

\begin_layout Section
Regularization and model selection 
\end_layout

\begin_layout Standard
How do we select among different models for a learning problem? How can
 we automatically select a model that represents a good tradeoff between
 bias and variance?
\end_layout

\begin_layout Standard
For the sake of concrectness, we assume we have some finite set of models
 
\begin_inset Formula $M=\{M_{1},\dots,M_{d}\}$
\end_inset

that we're trying to select among.
 
\end_layout

\begin_layout Subsection
Cross validation
\end_layout

\begin_layout Standard
Given a training set 
\begin_inset Formula $S$
\end_inset

, our intuition might be to train each model on 
\begin_inset Formula $S$
\end_inset

 and then choose the hypothesis with the smallest training error.
 This does not work.
 Consider choosing the order of a polynomial.
 This algorithm would always choose the highest order possible, leading
 to high variance.
 
\end_layout

\begin_layout Standard
A better algorithm is 
\series bold
hold-out cross validation
\series default
 (also called 
\series bold
simple cross validation
\series default
):
\end_layout

\begin_layout Enumerate
Randomly split 
\begin_inset Formula $S$
\end_inset

 into 
\begin_inset Formula $S_{train}$
\end_inset

(maybe 70% of the data) and 
\begin_inset Formula $S_{CV}$
\end_inset

(the remaining data).
 
\begin_inset Formula $S_{VC}$
\end_inset

 is called the hold-out cross validation set.
 
\end_layout

\begin_layout Enumerate
Train each model 
\begin_inset Formula $M_{i}$
\end_inset

 on 
\begin_inset Formula $S_{train}$
\end_inset

to get some hypothesis 
\begin_inset Formula $h_{i}$
\end_inset

.
 
\end_layout

\begin_layout Enumerate
Select the hypothesis 
\begin_inset Formula $h_{i}$
\end_inset

 that has the smallest error 
\begin_inset Formula $\hat{\epsilon}_{S_{CV}}(h_{i})$
\end_inset

 on the hold-out corss validation set.
 
\end_layout

\begin_layout Standard
By testing on a set that the models were not trained on, we obtain a better
 estimate of our hypotheses' true generalization error.
 Usually somewhere between 25% and 33% of the data is used in the hold-out
 cross validation set.
 Optionally we can also make a fourth step where after we choose our model
 we retrain it on the entire training set 
\begin_inset Formula $S$
\end_inset

.
 
\end_layout

\begin_layout Standard
The disadvantage here is that we're 
\begin_inset Quotes eld
\end_inset

wasting
\begin_inset Quotes erd
\end_inset

 about 30% of our data.
 There will definitely be a point where we can only train of 0.7
\begin_inset Formula $m$
\end_inset

, instead of 
\begin_inset Formula $m$
\end_inset

 training examples.
 So, in learning problems where we have few data (say, 
\begin_inset Formula $m=20$
\end_inset

) we would rather use another method, called 
\series bold
k-fold cross validation
\series default
:
\end_layout

\begin_layout Enumerate
Randomly split 
\begin_inset Formula $S$
\end_inset

 into 
\begin_inset Formula $k$
\end_inset

 disjoint subsets of 
\begin_inset Formula $m/k$
\end_inset

 training examples each.
 We'll call these subsets 
\begin_inset Formula $S_{1},\dots,S_{k}$
\end_inset

.
 
\end_layout

\begin_layout Enumerate
For each model 
\begin_inset Formula $M_{i}$
\end_inset

, we evaluate it as follows:
\begin_inset Newline newline
\end_inset


\begin_inset Formula $\qquad$
\end_inset

 For 
\begin_inset Formula $j=1,\dots,k$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $\qquad\qquad$
\end_inset

 Train the model 
\begin_inset Formula $M_{i}$
\end_inset

on all data except 
\begin_inset Formula $S_{j}$
\end_inset

 to get some hypothesis 
\begin_inset Formula $h_{ij}$
\end_inset

.
 Test this hypothesis 
\begin_inset Formula $h_{ij}$
\end_inset

 on 
\begin_inset Formula $S_{j}$
\end_inset

 to get 
\begin_inset Formula $\hat{\epsilon}_{s_{j}}(h_{ij})$
\end_inset

.
 
\begin_inset Newline newline
\end_inset


\begin_inset Formula $\qquad$
\end_inset

The estimated generalization error of the model 
\begin_inset Formula $M_{j}$
\end_inset

 is then calculated as the average of the 
\begin_inset Formula $\hat{\epsilon}_{S_{j}}(h_{ij})$
\end_inset

 (averaged over 
\begin_inset Formula $j$
\end_inset

).
 
\end_layout

\begin_layout Enumerate
Pick the model 
\begin_inset Formula $M_{i}$
\end_inset

 with the lowest estimated generalization error and retrain it on the whole
 training set.
 The resulting hypothesis is then output as our final answer.
 
\end_layout

\begin_layout Standard
A ususal choice for 
\begin_inset Formula $k$
\end_inset

 as a number of folds would be around 
\begin_inset Formula $k=10$
\end_inset

.
 While the fraction of data held out is now only 
\begin_inset Formula $1/k$
\end_inset

 -and therefore much smaller-, this method may also be more computionally
 expensive.
 
\end_layout

\begin_layout Standard
When we're using the extreme choice of 
\begin_inset Formula $k=m$
\end_inset

 to leave out as little data as possible, we call this method the 
\series bold
leave-one-out cross validation .
 
\end_layout

\begin_layout Standard
These methods can also be used to evaluate a single model or algorithm.
 If we want to estimate our future performance, cross validation can give
 a reasonable way of doing so.
 
\end_layout

\begin_layout Subsection
Feature selection
\end_layout

\begin_layout Standard
Imagine you have a supervised learning problem where the number of features
 
\begin_inset Formula $n$
\end_inset

 is very large but you suspect that only a small number of features is actually
 relevant.
 Even with a linear algorithm, overfitting would still be a potential problem
 unless the training set is fairly large.
 We want to choose only the features that are relevant to us.
 A possible way of doing so is called 
\series bold
forward search
\series default
:
\end_layout

\begin_layout Enumerate
Initialize 
\begin_inset Formula $F=\emptyset$
\end_inset


\end_layout

\begin_layout Enumerate
Repeat {
\begin_inset Newline newline
\end_inset

(a) For 
\begin_inset Formula $i=1,\dots,n$
\end_inset

 if 
\begin_inset Formula $i\notin F$
\end_inset

, let 
\begin_inset Formula $F_{i}=F\cup\{i\}$
\end_inset

and use some version of cross validation to evaluate features 
\begin_inset Formula $F_{i}$
\end_inset

(I.e.
 train you algorithm only on the features in 
\begin_inset Formula $F_{i}$
\end_inset

and estimate its generalization error.)
\begin_inset Newline newline
\end_inset

(b) Set 
\begin_inset Formula $F$
\end_inset

 to be the best feature subset found on step (a).
 
\begin_inset Newline newline
\end_inset

}
\end_layout

\begin_layout Enumerate
Select and output the best feature subset that was evaluated during the
 entire search procedure.
 
\end_layout

\begin_layout Standard
The outher loop can be done as many times as the number of features wanted
 or till all features are chosen.
 This algorithm is an instantiation of 
\series bold
wrapper model feature selection
\series default
, since it 
\begin_inset Quotes eld
\end_inset

wraps
\begin_inset Quotes erd
\end_inset

 around the algorithm and repeatedly calls the algorithm to evaluate how
 well it does with different subsets.
 Similarly we can also do 
\series bold
backward search
\series default
 where we start with the entire set and delete one by one, till we are satisfied.
 These algorithms work usually quite well but can be computationally expensive.
 
\end_layout

\begin_layout Standard

\series bold
Filter feature selection
\series default
 methods give heurisitc, but cheaper ways of chhosing feature subsets.
 The idea is to calculate a simple score that tells us how informative each
 fature is about the labels.
 Then we just choose the 
\begin_inset Formula $k$
\end_inset

 features with the best scores.
 
\end_layout

\begin_layout Standard
In practice, a common way of doing so is to choose 
\begin_inset Formula $S(i)$
\end_inset

 to be the 
\series bold
mutual information 
\begin_inset Formula $MI(x_{i},y)$
\end_inset

 
\series default
between 
\begin_inset Formula $x_{i}$
\end_inset

and 
\begin_inset Formula $y$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
MI(x_{i},y)=\sum_{x_{i}\in\{0,1\}}\sum_{y\in\{0,1\}}p(x_{i},y)log\frac{p(x_{i},y)}{p(x_{i})p(y)}
\]

\end_inset

Note, that this equation assumes that the 
\begin_inset Formula $x_{i}$
\end_inset

and 
\begin_inset Formula $y$
\end_inset

 are binary-valued.
 The probabilities can be estimated according to their empirical distributions
 on the training set.
 Intuitively, this gives a measure of how different the probability distribution
s 
\begin_inset Formula $p(x_{i},y)$
\end_inset

 and 
\begin_inset Formula $p(x_{i})p(y)$
\end_inset

 are.
 If they are independent, then 
\begin_inset Formula $p(x_{i},y)=p(x_{i})p(y)$
\end_inset

 and the score would be small.
 
\end_layout

\begin_layout Standard
A way to choose how many features you want to use is again cross validation.
\end_layout

\begin_layout Subsection
Bayesian statistics and regularization
\end_layout

\begin_layout Standard
This will be another tool against overfitting.
 For maximum likelihood, we chose our parameters according to
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Theta_{ML}=arg\underset{\Theta}{max}\prod_{i=1}^{m}p(y^{(i)}|x^{(i)};\Theta).
\]

\end_inset

In our previous discussions, 
\begin_inset Formula $\Theta$
\end_inset

is not random, just unknown and it's our just to come up with procedures
 to estimate it.
 An alterative approach is the 
\series bold
Bayesian
\series default
 view, where we think of 
\begin_inset Formula $\Theta$
\end_inset

as a random variable with unkown value.
 We would specify a 
\series bold
prior distribution
\series default
 
\begin_inset Formula $p(\Theta)$
\end_inset

 on 
\begin_inset Formula $\Theta$
\end_inset

that expresses our prior beliefs.
 Given a training set, we can then calculate the posterior beliefs on the
 parameters
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(\Theta|S)=\frac{p(S|\Theta)p(\Theta)}{p(S)}=\frac{(\prod_{i=1}^{m}p(y^{(i)}|x^{(i)},\Theta))p(\Theta)}{\int_{\Theta}(\prod_{i=1}^{m}p(y^{(i)}|x^{(i)},\Theta)p(\Theta))d\Theta}
\]

\end_inset

Here, 
\begin_inset Formula $p(y^{(i)}|x^{(i)},\Theta)$
\end_inset

 comes from our model.
 For example, using Bayesian logistic regression: 
\begin_inset Formula $p(y^{(i)}|x^{(i)},\Theta)=h_{\Theta}(x^{(i)})^{y^{(i)}}(1-h_{\Theta}(x^{(i)}))^{(1-y^{(i)}}$
\end_inset

.
 To make a prediction we can compute the posterioir distribution on the
 class label:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(y|x,S)=\int_{\Theta}p(y|x,\Theta)p(\Theta|S)d\Theta
\]

\end_inset


\end_layout

\begin_layout Standard
This procedure is thought of as 
\begin_inset Quotes eld
\end_inset

fully Bayesian
\begin_inset Quotes erd
\end_inset

 prediction.
 Unfortunatelly, it is usually very computationally expensive.
 Thus, in praxis we will usually approximate the posterior distribution
 for 
\begin_inset Formula $\Theta$
\end_inset

.
 The 
\series bold
MAP (maximum a posteriori)
\series default
 estimate for 
\begin_inset Formula $\Theta$
\end_inset

 is given by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Theta_{MAP}=arg\underset{\Theta}{max}\prod_{i=1}^{m}p(y^{(i)}|x^{(i)},\Theta)p(\Theta).
\]

\end_inset


\end_layout

\end_body
\end_document
